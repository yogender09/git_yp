$Header: /cvs/juniper/sw-projects/os/nsr/p2mp-nsr-funcspec.html,v 1.5 2010/03/09 19:21:59 anantha Exp $
<html>
<title>P2MP-NSR Functional/Design Specification</title>
<h1><center>P2MP-NSR Functional Specification</center></h1>
<h4>Last Updated: Mon Dec  7 12:16:52 PST 2009<h4>
<pre>
RLI - <a href="https://deepthought.juniper.net/app/do/showView?taskCode=all&record_number=9023&tableName=RLI">9023</a> NSR:P2MP for transit only
PR  - <a href=http://gnats.juniper.net/web/default/488772">488772</a>
Rel - JunOS 10.7
Dev - <a href="mailto:anantha@juniper.net">Anantharamu Suryanarayana</a>

Copyright (C) 2005, Juniper Networks, Inc.

NOTICE: This document contains proprietary and confidential information of
        Juniper Networks, Inc. and must not be distributed outside of the
        company without the permission of Juniper Networks engineering.
</pre>

<h2>Table Of Contents</h2>
<ol>
<li> <a href="#Intr">INTRODUCTION</a></li>
<li> <a href="#Plan">PLANNED SCHEDULE</a></li>
<li> <a href="#Refe">REFERENCES</a></li>
<li> <a href="#Func">FUNCTIONALITY</a></li>
<li> <a href="#Pate">PATENT OPPORTUNITIES</a></li>
<li> <a href="#Cave">CAVEATS</a></li>
<li> <a href="#othe">OTHER REQUIREMENTS</a></li>

<li> <a href="#Impl">IMPLEMENTATION DETAILS</a></li>
<ol>
<li> <a href="#p2mp-nsr-infra">P2MP-NSR Infrastructure</a></li>
<li> <a href="#p2mp-nsr-transit">P2MP-NSR Transit</a></li>
<li> <a href="#p2mp-nsr-egress">P2MP-NSR Egress</a></li>
<li> <a href="#p2mp-nsr-ingress">P2MP-NSR Ingress</a></li>
<li> <a href="#prot">FRR, Link Protection and Node Protection</a></li>
<li> <a href="#grac">P2MP-RSVP Graceful Restart</a></li>
</ol>

<li> <a href="#perf">PERFORMANCE ISSUES</A></li>
<li> <a href="#comp">COMPATIBILITY ISSUES</a></li>
<li> <a href="#secu">SECURITY ISSUES</a></li>
<li> <a href="#plat">PLATFORMS SUPPORTED</a></li>
<li> <a href="#swit">Graceful RE Switch-Over (GRES), or ISSU Impact</a></li>
<li> <a href="#nsri">NSR IMPACT</a></li>
<li> <a href="#aggr">Aggregated Ethernet/SONET Support</a></li>
<li> <a href="#sdki">SDK Impact</a></li>
<li> <a href="#serv">Services / JSF (JUNOS Services Framework) Impact</a></li>
<li> <a href="#mult">MULTI-CHASSIS SUPPORT</a></li>
<li> <a href="#64bi">64-BIT SUPPORT</a></li>

<li> <a href="#inte">INTEROPERABILITY ISSUES</a>
<li> <a href="#scal">SCALABILITY ISSUES</a></li>
<li> <a href="#debg">DEBUG-ABILITY ISSUES</a></li>
<li> <a href="#Test">UNIT AND FUNCTIONAL TESTING</a></li>
<li> <a href="#CLIC">CLI Commands Reference</a></li>
<li> <a href="#Conf">Sample Configuration</a></li>
<li> <a href="#ShowCmdMaster">Sample Show command outputs in Master</a></li>
<li> <a href="#ShowCmdBackup">Sample Show command outputs in Backup</a></li>

<li> <a href="#note">NOTES</a></li>
<li> <a href="#glos">GLOSSARY</a></li>
<li> <a href="#revi">REVIEW COMMENTS</a></li>
</ol>
<pre>

<hr><a name="Intr"></a><h2>INTRODUCTION</h2>
Essentially this project has been divided into 3 MEDIUM RLI sized sub projects.

<b>1. NSR Infrastructure support for flood next-hops in KRT</b>
    RLI: <a href="https://deepthought.juniper.net/app/do/showView?taskCode=all&record_number=9023&tableName=RLI">9023</a>
    PR : <a href=http://gnats.juniper.net/web/default/488772">488772</a>
    NPI: NSR support in RPD
    Related RLIs: <a href="https://deepthought.juniper.net/app/do/showView?taskCode=all&record_number=2609&tableName=RLI">2609 (GRES for MPLS transit P2MP LSPs)</a>
    Customer: ???
    Target Release: 10.7R1

       o Design and implementation of flood next-hop look up routine based on
         application specific opaque TLVs and branch LSPs

       o Need to maintain branches nh-list separately from that of
         application's inside the flood next-hop

<b>2. RSVP-P2MP P2MP Transit NSR</b>
       o RLI: Falls under RLI 9023 listed above.
       o Consistent bypass selection
       o Enable P2MP packets reception in Standby (From Master)
       o Enable P2MP packets send in Master (towards Standby)
       o Egress LSPS - Interaction with VT Interface
       o P2MP LSP Branch re-merge - Synchronization with master required

       * With Infrastructure changes in place [1], rest should fall in place
         automatically

<b>3. RSVP-P2MP Ingress NSR</b>
    RLI: 9023
    PR : 
    NPI: NSR support in RPD
    Related RLI: <a href="https://deepthought.juniper.net/app/do/showView?taskCode=all&record_number=2826&tableName=RLI">2826 (GRES for MPLS ingress P2MP LSPs)</a>
    Customer: ???
    Target Release: 10.9R1

    o Synchronize P2MP-PVC state between Master and Standby (PVCID, TunnelID,
         SubgroupID, etc.)
       o Create and manage p2mp_pvc_repl_t data base in Master and Standby
       o show mpls replication p2mp-pvc
       o Make-Before-Break of P2MP LSPs in standby

<hr><a name="Plan"></a><h2>Planned Schedule for projects 1, 2, 3 listed above</h2>
o 2 is dependent on 1
o 3 is dependent on 2
o 1 and 2 can be done in parallel (with 1 person dedicated in each project)
o 2 and 3 can be done together only in minimum 2 development release cycles
  (6 months) - Downside is that too much testing effort needs to be spent in one
  go to test all the three projects at the same time.
o One quarter required to support [sys] testing effort for 1 and 2

<b>Conclusion: 1 and 2 will be done together for 10.3R1 by one person and 3 is targeted for 10.5R1</b>

<hr><a name="Refe"></a><h2>REFERENCES</h2>
<a href="http://cvs.juniper.net/cgi-bin/viewcvs.cgi/sw-projects/os/nsr/rsvp-funcspec.txt?rev=HEAD">RSVP-NSR Functional Specification</a>
<a href="http://cvs.juniper.net/cgi-bin/viewcvs.cgi/sw-projects/os/nsr/rsvp-design.txt?rev=HEAD">RSVP-NSR Design Specification</a>
<a href="http://cvs.juniper.net/cgi-bin/viewcvs.cgi/*checkout*/sw-projects/mpls/p2mp/graceful-restart/ingress_p2mp_gres_spec.txt">P2MP Graceful Restart</a>
<a href="https://confluence.jnpr.net/confluence/display/RPD/Ingress+traffic+loss+during+make-before-break+of+P2MP+LSP">Make Before Break for P2MP</a>
<a href="http://cvs.juniper.net/cgi-bin/viewcvs.cgi/sw-projects/mpls/ldp/p2mp/p2mp_ldp_lsp_func_spec.txt?rev=HEAD">P2MP LDP Functional spec</a>
<a href="http://www.convergedigest.com/bp/bp1.asp?ID=574&ctgy">P2MP LSPs Optimization</a>
<a href="http://www.juniper.net/techpubs/software/junos/junos90/feature-guide/configuring-traffic-engineering-p2mp-lsps-in-provider-tunnels.html">rsvp tunnel-services</a>
<a href="http://cvs.juniper.net/cgi-bin/viewcvs.cgi/sw-projects/okra/shared/RLI7689_rpd_p2mp_to_comp_spec.txt?rev=HEAD">Migrating P2MP next-hops from flood to composite</a>

<hr><a name="Func"></a><h2>FUNCTIONALITY</h2>
This project is essentially to provide Non-Stop-Routing NSR functionality for
P2MP static LSPS. Please see <a href="#Refe">References</a> for additional
information wrt NSR functionality.

<b>Goals</b>

o Bring UP P2MP LSPs on standby RE and synchronize its events with the master RE.
o Synchronize p2mp flood/composite next-hop information in krt
o Achieve hit-less fail-over in stable conditions for traffic passing through
  P2MP LSPs. <br>

<b>Non-Goals</b>

o Support NSR for dynamically created P2MP LSPs. e.b. VPLS, ngen-MVPNs, etc.
o Hit-less fail-over during unstable conditions (in the middle of
  make-before-break, network change events, etc.). (However minimizing
  traffic-loss is one of the desired goal of this NSR project)

<b>APIs/Messages</b>
  N/A

<b>CLI Config</b>
  None

<b>JUNOSScript</b>
  N/A

<b>J-Web Quick Configuration and Monitor Screen</b>
  N/A

<b>SNMP</b>
  None

<b>Syslog - ERRMSG</b>
  After RE switch-over, P2MP LSPs are scanned for sanity and compatibility 
  between next-hops learned between Kernel/KRT and Application/RSVP. If any
  mis-match is found, new set of next-hops as learned from the application must
  be reprogrammed into Kernel/PFE. Upon such events, it is desirable to indicate
  it using a Syslog message.

<b>Assumptions</b>
  There is no specific assumption being made so far.

<b>Constraints and limitations</b>
  This project involves changes to both RPD Infrastructure and Application (Tag
  and RSVP). At the time of this writing, infrastructure part is also changing
  due to conversion of Flood next-hops to Composite. (RLI 7689). There are some
  assumptions in this part that integration would be smooth and result
  flaw-less. But only actual implementation and integration can reveal any
  unknown intricate issue that has not been accounted in this document so far.

<b>Dependencies and interactions with other components in the system</b>
  None

<hr><a name="Pate"></a><h2>PATENT OPPORTUNITIES</h2>
There is no major aspect in this project that can be patented. However, the idea
that NSR can be achieved seamlessly if flood-nexthops learned from the the kernel
in backup matches with the flood-nexthops (branches) as created by standby
RSVP-P2MP application

<hr><a name="Cave"></a><h2>CAVEATS</h2><b>
o NO NSR support for dynamically created P2MP LSPs (e.g. MVPN, VPLS) planned yet
o Initial NSR support for only Transit and Egress P2MP LSPs.
o Ingress P2MP LSPs NSR support would come in subsequent release (after transit).
o lsp statistics are currently maintained per sub lsp. All caveats that exist
  today wrt clear lsp statistics continue to apply for NSR as well.
o If switch-over happens during LSP remerge leader election (or at any time when
  master and standby are out of sync wrt remerge leader selection), some packet
  loss is to expected as new set of next-hops get programmed.
o Egress: Upstream label allocation is not supported for NSR.
o No support for P2MP Node protection NSR planned yet (Node protection itself is
  just getting planned)
o Link protection for P2MP LSPs NSR support would come in subsequent release
  (after transit).

</b>

<hr><a name="othe"></a><h2>OTHER REQUIREMENTS</h2>
o In the case of make-before-break of a P2MP tunnel, the lsp-id will change.

o For RSVP P2MP tunnels, the key will be
  {client-id, P2MP-ID, tunnel-id, extended-tunnel-id, lsp-id}
    The lsp-id will be different during a reroute of a LSP.

  This isn't true for CCC and other applications that create flood-nh. It all
  depends on how these applications intend to use the flood-nh. Currently, the
  applications need to use a unique key.

o Interactions with other components such as IGP and static route component.
  Need to make sure that static route component is correctly notified an and when
  changes happen to p2mp lsps. (that may result in update to flood next-hops)

o CSPF for parallel links: At present, when working with parallel pinks, CSPF 
  picks one of the link as the selected link for p2mp sub-lsps that share the
  same path. i.e. if there are 'n' sub-lsps going from node 1 to next-hop node 2
  and if there are 'm' links between 1 and 2, then the same link will be picked by
  all 'n' sub-lsps, by default. 

  Backup rpd should also pick the same interface in order to keep control path
  and data path in sync and thus reduce traffic loss after RE switch-over.

<hr><h2><a name="Impl"><a>IMPLEMENTATION DETAILS</h2>
Implementation details of this project are described in detail in the following
sections.

<hr><h2><a name="p2mp-nsr-infra"><a>P2MP-NSR Infrastructure support for flood next-hops in KRT</h2>
One of the fundamental requirements from rpd-krt infrastructure in standby rpd is
to create and maintain flood next-hops like how it is done in the master rpd.
This is done by listening to RTSOCK messages from the kernel and taking necessary
actions such as creating new flood-nhs, deleting old ones and modifying existing
ones.

Care has to be taken to ensure that if application has already created a flood,
then krt uses the same node instead of creating a new one. 

o Two lists of next-hops has to be maintained inside krt_floodnh_t data
  structure. Define following new APIs. Following APIs are defined that make
  the over-all changes of minimal impact.
<b><i>
diff -r 440d17bdd8aa src/junos/usr.sbin/rpd/os/krt_floodnh.c
--- a/src/junos/usr.sbin/rpd/os/krt_floodnh.c	Thu Oct 15 19:26:23 2009 -0700
+++ b/src/junos/usr.sbin/rpd/os/krt_floodnh.c	Tue Nov 03 12:48:28 2009 -0800
@@ -61,7 +61,8 @@ typedef struct __krt_floodnh_PRIVATE__ {
 				    /* a delete is queued and a local change */
                                     /* is made.  if the delete is canceled,  */
                                     /* this reminds us to send down a change.*/
-    krt_nhlist_t      *kf_nhlist;   /* list of branch nexthops */
+    krt_nhlist_t      *kf_applic_nhlist;/* branch nexthops added by apps */
+    krt_nhlist_t      *kf_kernel_nhlist;/* branch nexthops added by kernel(krt) */
     tag_auto_policer_t kf_auto_policer; /* flood nexthop auto policer */
     int                kf_krtt_id;      /* krtt table id used for VPLS */
     u_int8_t           kf_nhsubtype;    /* Nexthop subtype determine by 
@@ -71,6 +72,24 @@ typedef struct __krt_floodnh_PRIVATE__ {
 } krt_floodnh_t;
</i></b>
    1. kf_applic_nhlist: Contains the list of branch next-hops added by
       application(s) like RSVP.

    2. kf_kernel_nhlist: Contains the list of branch next-hops added by
       kernel (via KRT module).

       kf_nhlist_select(KF_NH_LIST_SELECT_APPL or KF_NH_LIST_SELECT_KERNEL)
         Set to mode for the rest of the APIs defined below.

       kf_nhlist (krt_floodnh_t *floodnh)
         Retrieves nhop list from currently selected mode.

       kf_nhlist_p (krt_floodnh_t *floodnh)
         Retrieves the address of current next-hop list to work with.

       kf_nhlist_key (uint branch_position)
         Retrieves nhop key for currently selected next-hop list for a
         particular branch

       kf_nhlist_key_p (uint branch_position)
         Retrieves address of nhop key for currently selected next-hop list
         for a particular branch

       If it looks cleaner, we can enhance all the APIs to explicitly take the
       next-hop list to operate on. This adds more clarity but makes all the
       nested existing functions to be aware of this information unnecessarily.
       Actual method to use can only be determined during actual implementation.
       

o Modify krt_floodnh.c to use above defined APIs where ever it needs access to
  branch next-hops list.

o Modify 'show krt flood-nexthop' to show both next-hops list.

<b><i>
$ jssh pro9-b1 'cli sh krt flood-nexthop'
Index: 634, Address: 8e69d80
   Locks: 3, References: 1
   Subtype: P2MP, Table ID: 0xFFFFFFFF
   key: client: 0x01 p2mp_id: 0x3a5ff0a tunnel_id: 0x5ccc ext_tunnel_id: 0x3a5ff0a lsp_id: 0x0100 label: -1 
   Number of Nexthops: 2   Index: 634    (Added by kernel - Match)
   Nexthops: 103CF008 1035F408
        Next hop: 1.1.99.8 via fe-1/3/0.99 weight 0x1, selected
        Label operation: Push 300896
        Next hop: 1.1.6.7 via fe-1/3/0.6 weight 0x1, selected
        Label operation: Push 300720
   Number of Nexthops: 2   Index: 634    (Added by Applications)
   Nexthops: 103CF008 1035F408
        Next hop: 1.1.99.8 via fe-1/3/0.99 weight 0x1, selected
        Label operation: Push 300896
        Next hop: 1.1.6.7 via fe-1/3/0.6 weight 0x1, selected
        Label operation: Push 300720
</i></b>

o One of the most bug prone areas seems to be the area in the  flood next-hops
  created by applications and krt. If they do not match correctly, then we will
  have packet drops after the switch-over. Hence it is necessary to add
  extensive tracing capabilities to these areas.

  One e.g. is to add a match-nomatch result to the show command itself.

<i><b>
$ jssh pro9-b1 'cli sh krt flood-nexthop' | \grep -i kernel 
   Number of Nexthops: 0   Index: 0      (Added by kernel - MisMatch)
   Number of Nexthops: 2   Index: 633    (Added by kernel - MisMatch)
   Number of Nexthops: 1   Index: 0      (Added by kernel - MisMatch)
   Number of Nexthops: 0   Index: 0      (Added by kernel - MisMatch)
   Number of Nexthops: 0   Index: 631    (Added by kernel - MisMatch)
   Number of Nexthops: 2   Index: 634    (Added by kernel - Match)
</b></i>

o Add label as an additional item to p2mp lsp key of flood-nexthops
   Currently, p2mp creates unique flood next-hops for every p2mp lsp that share
   the same phop and outgoing interface. Because of this, we can have scenarios
   where a given p2mp lsp can have multiple flood next-hops. Hence we need to
   add label as part of the application key set.

   e.g.

              ------- D
      1      |
   A ======= B ------ C
      2

   Sub-lsp 1: A-B-C (where A-B uses link 1)
   Sub-lsp 2: A-B-D (where A-B uses link 2)

   There will be 2 routes (and flood nexthops) at B in mpls.0 for the same p2mp
   tunnel/session.


<b><i>
@@ -93,6 +93,7 @@ typedef struct krt_p2mp_key {
     u_int16_t tunnel_id;      /* p2mp Tunnel ID - dst port */
     u_int32_t ext_tunnel_id;  /* Extended Tunnel ID - lo0 src address*/
     u_int16_t lsp_id;         /* LSP-ID */
+    u_int32_t label;          /* LSP-Label Value */
 } krt_p2mp_key_t;
</i></b>
 
   This label has to TLVized and sent across from Master RPD to Standby RPD.
   'show krt flood-nexthops' command should now show label as well, as part of
   the application key-set.

o krt_floodnh_set_nhidx() should reset existing index before setting to a new one
    In the new model, flood next-hops are created by both applications and krt
    through out the life of the standby rpd. Hence, depending on the order of
    arrival, we may have to modify existing next-hops. 

o This is one of the important change to krt_floodnh.c module.
  krt_floodnh_branch_add() currently always tries to add a new flood-nh
  irrespective of the caller (krt or rsvp). In standby NSR mode, we how ever 
  need to check if one already exists and if so, continue to use the existing
  flood-nh entry.

<b><i>
@@ -1446,17 +1491,32 @@ krt_floodnh_branch_add (krt_flnh_handle 
      */
     assert(rt_nexthops_type(brnh) == RT_NH_ROUTER);
 
+    if (key) {
+        existing_flnh = krt_floodnh_db_lookup_internal(key);
+    } else {
+        existing_flnh = NULL;
+    }
+
     if (cur_floodnh) {
 	floodnh = handle_to_ptr(krt_floodnh, cur_floodnh);
     } else {
-	floodnh = krt_floodnh_alloc();
+
+        /*
+         * Check if there already exists an entry. If so, use it.
+         */
+        if (existing_flnh && !krt_task_re_mode_master) {
+	    floodnh = existing_flnh;
+            krt_floodnh_lock_internal(floodnh);
+        } else {
+	    floodnh = krt_floodnh_alloc();
+        }
     }
</i></b>

<h3><u>Composite and non-composite flood-nexthops</u></h3>
Currently, flood-nexthops has its own type in the kernel called flood. However,
this is changing and flood-nexthops are converted to composites. Unfortunately,
there will be modes where KRT continues to act in dual mode, there by flood
nexthops are maintained in both forms, though only in one form at any time.

This item again introduces significant complexity to development and testing.
It is hard to do any design estimate upfront as code it changing constantly.

However, the underlying assumption is that composite/flood nexthops and 
krt_flood_nh use a clean boundary to interface with and only work with the
list of next-hops maintained inside krt_flood_nh.

This is also platform specific and hence adds additional testing challenges.

<hr><h2><a name="p2mp-nsr-transit"><a>P2MP-NSR Transit</h2>
<B><u>P2MP Re-merge leader election</u></b>

Current p2mp-remerge leader election algorithm does not fit well from NSR
perspective because it is based on the order of arrival of LSPs.

i.e, since the first PSB in the remerge list is always elected as the leader
(and hence its next-hop is the actual flood next-hop installed), we cannot
easily make standby follow the same notion.

On the other hand, if we were to make the re-merge logic to pick the head always
deterministic, say based on the PSB that has the largest selfID, then things
would fall seem-less from the NSR perspective.

But it has certain implications when remerge candidate lsp branches come
up. As we could flip the leader from one psb to another, we will have to install a
discard next-hop for the old leader and install a new flood nexthop for the new
leader. So, this can lead to temporary glitches like traffic loss if discard
makes it way first, or duplicates if flood makes it to the hardware first.

Hence alternative approach of replicating remerge leader information has been
considered. If we synchronize through rsvp-psb replication, who the currently
selected merge leader is, standby can follow the same semantics as the master.

This requires following changes at a high level.

o Add psb-&gt;remerge_head Boolean to PSB data structure.
o Replicate remerge_head Boolean from master to standby.
o During normal operations, let Master and Standby continue to elect remerge
  leaders like how they normally do.
o Standby how-ever has to take certain precautions and 
      - Prefer the leader as elected by Master when ever possible
      - Reelect the leader upon notification for remerge_head status change
        notification from the Master via lib-mirror.
o Add remerge-head state to 'show rsvp replication path-state detail' command
o Add extensive logging and tracing capabilities to be able to effectively debug
  this new logic added to standby remerge logic

e.g. jssh pro9-b1 'cli sh rsvp replication path-state detail \| display xml' | \grep -i remerge
            <path-state-p2mp-remerge-head>No</path-state-p2mp-remerge-head>
            <path-state-p2mp-remerge-head>Yes</path-state-p2mp-remerge-head>

<hr><h2><a name="p2mp-nsr-egress"></a>P2MP-NSR Egress</h2>
<b><u>Ultimate Hop Popping</u></b>

While most of the work currently done for RSVP Egress LSPs apply as is to p2mp
lsps as well, "P2MP Ultimate Hop Popping (UHP)" feature may not work correctly
as is. 

There are two missing pieces.

1. Currently RSVP-RSB is brought up in the standby as part of the rsb
   replication entry resolution process. However, this does not take care of
   ultimate hop-popping events.

2. Even if solve (1) by adding necessary hooks to the standby rsb replication
   resolution process, things may not work in sync between master and standby
   because of the way RSVP hooks VT-Interfaces dynamically into egress next-hops
   in order to further IP process ultimate hop popped packets.

   Please see <a href="http://www.juniper.net/techpubs/software/junos/junos90/feature-guide/configuring-traffic-engineering-p2mp-lsps-in-provider-tunnels.html">rsvp tunnel-services</a> for configuration details of this feature.

   In order to solve, standby should force the use of the same vt interface 
   during penultimate hop popping setup process, as the master does. This egress
   interaction is already available in replicated PSBs as part of next-hops.

Testing 1 and 2 is a slightly difficult process because RSVP only creates and
uses as many VT physical interfaces present in the router. To solve this, a
minor fix is proposed, where in RSVP would create "n" interfaces per vt
interface and use them as if they are different vt interfaces. n still defaults
to 1 and hence should not affect production code. Also, in order to make sure
that standby follows master in vt interface selection, a randomized order can be
induced in the master. (Again, only for function testing purposes)

<hr><h2><a name="p2mp-nsr-ingress"><a>P2MP-NSR Ingress</h2>

o Modify rsvp replication encode and decode routines to correctly encode and
  decode p2mp pvc information.

o Replicate p2mp-pvc-id and p2mp-dst-port from master to standby. Currently master
  independently chooses any unique id available using tag_bit_alloc() API.
  Standby needs to use the same id.

  [ But aren't these already present as part of replicated psbs (the key of
    flood-nexthop) ??? ]

  The pvc-id is internal to the code. The dst-port is the same shown for each
  sub-lsp under 'show rsvp session extensive' -- the value against 'receiver'.
  Actual use of p2mp_pvc_id needs further investigation.


o Handle <b>make-before-break</b> correctly so that standby and master are still in
  sync after the completion of make-before-break

o Interaction from applications
    At present, NSR is supported for only static routes. Hooks are necessary in
    the standby to make sure that any other4 p2mp lsps (like those created from
    vpls, nggen-mvpn, ccc, etc.) do not come and stay up and give a false
    impression that it does work or have any undesired behavior.

TBD...

<hr><a name="prot"></a><h2>FRR, Link Protection and Node Protection</h2>
o Currently p2mp has support for only link protection
o FRR (Detour ?) is not supported for the native p2mp feature
o Global protection with rerouting using secondary paths at Ingress is also not
  not supported yet.

From NSR perspective, Link protection of individual branch lsps at PLR using
RSVP Bypass is the only key feature to be considered.

Since RSVP Bypass has similar notion to Ingress LSPs, this shall come in as part
of P2MP-NSR Ingress project. Care must be taken to ensure that all P2MP branches
sharing the same next-hop select the same RSVP Bypass LSP.

Currently, RSVP already replicates this information and hence no additional work
is expected in this area. However, in the initial phase when we support NSR for
only transit P2MP LSPs, link-protection must be disabled in the standby software.

<hr><a name="grac"></a><h2>P2MP-RSVP Graceful Restart</h2>
One of the critical impact of this project is to P2MP-RSVP graceful restart.
Though NSR and Graceful-Restart are mutually exclusive, underlying infrastructure
in KRT-FLOODNH module is quite common between the two.

With support for NSR, two next-hops list are maintained inside krt_floodnh_t
data structure, one maintained by KRT/Kernel and the other by applications like
RSVP. However, for graceful restart purposes, logic needs to be tweaked enough
to make sure that RSVP and KRT work on the same list of flood-nexthops.

This item of the project is applicable to both transit as well well as the
ingress sub-projects. This also increases the testing effort by a considerable
margin.

<hr><a name="perf"></a><h2>PERFORMANCE ISSUES</h2>
There is no additional performance improvement/degradation is expected off this
project. How ever, it is to be noted that hit-less switch over is not
guaranteed during double failures. i.e, if switch-over is done in the middle of
LSP switch-overs.

<hr><a name="comp"></a><h2>COMPATIBILITY ISSUES</h2>
Because the entire project is divided in to two, care has to be taken to make sure
that ISSU and compatibility to older releases work seem-lessly. Special care must
be taken to make sure that unsupported NSR features continue work seem-lessly
in the master before switch-over and cleanly after the switch-over in the new
master.

<hr><a name="secu"></a><h2>SECURITY ISSUES</h2>
N/A

<hr><a name="plat"></a><h2>PLATFORMS SUPPORTED</h2>
No specific exceptions

<hr><a name="swit"></a><h2>Graceful RE Switch-Over (GRES) or ISSU impact</h2>
All the NSR effort comes to use only after the switch-over after all. While most
of the effort is done before the switch-over to make sure that Standby RE has
all the necessary information as the master does, there is additional cleanup
that is necessary wrt P2MP LSPs flood-nexthops.

After the switch-over, all the flood-nexthops must be examined and checked for
match/mis-match between the two list of next-hops. This is similar to
route-nexthops reconciliation done for the unicast routes.

When ever there is a mis-match, the next-hops learned from Kernel must be deleted
and the those learned from the applications must be downloaded to pfe. This can
cause traffic loss.

To minimize this loss [low priority], next-hops already in kernel can be given
higher priority if they happen to exist in the application next-hops list as well.
This is only applicable if application list has more next-hops than that can be
downloaded to kernel/pfe.

<hr><a name="nsri"></a><h2>NSR IMPACT</h2>
This RLI is NSR specific and dedicated to provide NSR support for P2MP LSPs.

<hr><a name="aggr"></a><h2>Aggregated Ethernet/SONET Support</h2>
N/A

<hr><a name="sdki"></a><h2>SDK Impact</h2>
N/A

<hr><a name="serv"></a><h2>Services / JSF (JUNOS Services Framework) Impact</h2>
N/A

<hr><a name="mult"></a><h2>MULTI-CHASSIS SUPPORT</h2>
N/A

<hr><a name="64bi"></a><h2>64-BIT SUPPORT</h2>
N/A

<hr><a name="inte"></a><h2>INTEROPERABILITY ISSUES</h2>
This project is NSR specific and hence does not impose any inter-operability
issue.

<hr><a name="scal"></a><h2>SCALABILITY ISSUES</h2>
This project does not impose any new scale limitations onto P2MP LSPs per se.
What ever limitations that exist today regarding the number of branches per lsp,
number of next-hops per flood, etc. continue to remain the same.

However, due to various timing issues, it is very likely possible that many
issues get uncovered in the NSR logic being introduced in large scale test
environments. Areas that are particularly sensitive are flood-nexthops, and
lsp remerge scenarios.

Due to nature of the project (NSR), resources required to do scale testing
need upfront planning both at development and at sys-test.

<hr><a name="debg"></a><h2>DEBUG-ABILITY ISSUES</h2>
In order to easier trouble shooting and management, following minor enhancements
are desired but not a must to have.

o Enhance show krt flood-nexthops to take additional filtering arguments such as
  next-hop index, LSP destination, P2MP lsp name, etc.

o Add more counters, log messages and trace messages to krt_floodnh and
  p2mp_remerge modules.

<hr><a name="Test"></a><h2>UNIT AND FUNCTIONAL TESTING</h2>
Since P2MP is an existing feature with multitude of features, it would be
difficult and inefficient to test individual parts of the feature from NSR
perspective. It seems, time is better spent if we were to add NSR related checks
to existing p2mp regression scripts. Thus, we hopefully get maximum benefits
from relatively much less effort.

<b>There is an assumption here that we have a reliable set of p2mp regressions
that currently run and consistently pass. Apparently, that has not been the case
yet !
</b>

Initial attempt is of-course to get the current p2mp regression set pass with and
without NONSTOP_ROUTING set to TRUE (to force NSR mode)

Initial issues found: Certain configuration check failures in PIM perhaps
related to mvpn. That may need to be relaxed. This is additional work required
in components out side of TAG and RSVP.

<hr><a name="CLIC"></a><h2>CLI Commands Reference</h2>
show mpls p2mp-restart-database
show mpls lsp p2mp [detail | extensive]
show mpls lsp [detail | extensive]
show mpls path [detail | extensive]
show krt next-hops
<hr>
<h2><a name="Conf"></a>Sample Configuration</h2>
{master}[edit]
regress@pro9-b# show protocols mpls 
log-updown {
    /*

+=============================================================================+
|                                                                             |   
|                                                                             |   
|                                                                             |   
|     INGRESS--------R1---------PLR---------R2           R5--------------R7   |   
|        |   \                   |          |            |                    |   
|        |    \_______________   |          |            |                    |   
|        |                    \  |          |            |                    |   
|        |                     \ |          |            |                    |   
|       ING2---------------------R3---------MP---------PHOP                   |   
|                                                        |                    |   
|                                                        |                    |   
|                                                        |                    |   
|                                                      EGRESS                 |   
|                                                                             |   
|                                                                             |   
|                                                                             |   
+=============================================================================+
    
     */
    syslog;         
}
traffic-engineering bgp-igp;
label-switched-path P2MP_INGRESS-to-R7_1 {
    to 10.0.0.6;
    p2mp P2MP_1;
    primary BR2_via_R2;
}
label-switched-path P2MP_INGRESS-to-PHOP_2 {
    to 10.0.0.10;
    p2mp P2MP_1;
    primary BR3_via_ING2;
}
label-switched-path P2MP_INGRESS-to-EGRESS_3 {
    to 10.0.0.11;
    p2mp P2MP_1;
    primary BR1_via_R3;
}
path BR1_via_R3 {
    1.1.8.8 loose;
}
path BR2_via_R2 {
    1.1.7.4 loose;
}
path BR3_via_ING2 {
    1.1.6.7 loose;
}

<hr>
<h2><a name="ShowCmdMaster"></a>Sample Show Commands Output in Master</h2>

<b>Master: Ingress</b>

{master}[edit]
regress@pro9-b# run show mpls lsp p2mp              
Ingress LSP: 1 sessions
P2MP name: P2MP_1, P2MP branch count: 3
To              From            State Rt P     ActivePath       LSPname
10.0.0.10       10.255.165.3    Up     0 *     BR3_via_ING2     P2MP_INGRESS-to-PHOP_2
10.0.0.6        10.255.165.3    Up     0 *     BR2_via_R2       P2MP_INGRESS-to-R7_1
10.0.0.11       10.255.165.3    Up     0 *     BR1_via_R3       P2MP_INGRESS-to-EGRESS_3Total 3 displayed, Up 3, Down 0

Egress LSP: 0 sessions
Total 0 displayed, Up 0, Down 0

Transit LSP: 1 sessions
Total 0 displayed, Up 0, Down 0

{master}[edit]
regress@pro9-b# run show mpls lsp p2mp detail 
Ingress LSP: 1 sessions
P2MP name: P2MP_1, P2MP branch count: 3

10.0.0.10
  From: 10.255.165.3, State: Up, ActiveRoute: 0, LSPname: P2MP_INGRESS-to-PHOP_2
  ActivePath: BR3_via_ING2 (primary)
  P2MP name: P2MP_1
  LoadBalance: Random
  Encoding type: Packet, Switching type: Packet, GPID: IPv4
 *Primary   BR3_via_ING2     State: Up
    Priorities: 7 0
    SmartOptimizeTimer: 180
    Computed ERO (S [L] denotes strict [loose] hops): (CSPF metric: 43)
 1.1.6.7 S 1.1.11.8 S 1.1.1.9 S 1.1.4.10 S 
    Received RRO (ProtectionFlag 1=Available 2=InUse 4=B/W 8=Node 10=SoftPreempt 20=Node-ID):
          1.1.6.7 1.1.11.8 1.1.1.9 1.1.4.10

10.0.0.6
  From: 10.255.165.3, State: Up, ActiveRoute: 0, LSPname: P2MP_INGRESS-to-R7_1
  ActivePath: BR2_via_R2 (primary)
  P2MP name: P2MP_1
  LoadBalance: Random
  Encoding type: Packet, Switching type: Packet, GPID: IPv4
 *Primary   BR2_via_R2       State: Up
    Priorities: 7 0
    SmartOptimizeTimer: 180
    Computed ERO (S [L] denotes strict [loose] hops): (CSPF metric: 47)
 1.1.6.7 S 1.1.11.8 S 1.1.8.3 S 1.1.7.4 S 1.1.10.9 S 1.1.4.10 S 1.1.12.5 S 1.1.9.6 S 
    Received RRO (ProtectionFlag 1=Available 2=InUse 4=B/W 8=Node 10=SoftPreempt 20=Node-ID):
          1.1.6.7 1.1.11.8 1.1.8.3 1.1.7.4 1.1.10.9 1.1.4.10 1.1.12.5 1.1.9.6

10.0.0.11
  From: 10.255.165.3, State: Up, ActiveRoute: 0, LSPname: P2MP_INGRESS-to-EGRESS_3
  ActivePath: BR1_via_R3 (primary)
  P2MP name: P2MP_1
  LoadBalance: Random
  Encoding type: Packet, Switching type: Packet, GPID: IPv4
 *Primary   BR1_via_R3       State: Up
    Priorities: 7 0
    SmartOptimizeTimer: 180
    Computed ERO (S [L] denotes strict [loose] hops): (CSPF metric: 44)
 1.1.6.7 S 1.1.11.8 S 1.1.1.9 S 1.1.4.10 S 1.1.2.11 S 
    Received RRO (ProtectionFlag 1=Available 2=InUse 4=B/W 8=Node 10=SoftPreempt 20=Node-ID):
          1.1.6.7 1.1.11.8 1.1.1.9 1.1.4.10 1.1.2.11
Total 3 displayed, Up 3, Down 0

Egress LSP: 0 sessions
Total 0 displayed, Up 0, Down 0

Transit LSP: 1 sessions
Total 0 displayed, Up 0, Down 0

<b>Master: Transit</b>

{master}[edit]
regress@pro9-d# run show mpls lsp p2mp logical-system MP 
Ingress LSP: 0 sessions
Total 0 displayed, Up 0, Down 0

Egress LSP: 0 sessions
Total 0 displayed, Up 0, Down 0

Transit LSP: 3 sessions
P2MP name: P2MP_1, P2MP branch count: 3
To              From            State   Rt Style Labelin Labelout LSPname 
10.0.0.10       10.255.165.3    Up       0  1 SE  299952        3 P2MP_INGRESS-to-PHOP_210.0.0.11       10.255.165.3    Up       0  1 SE  299952   299872 P2MP_INGRESS-to-EGRESS_3
10.0.0.6        10.255.165.3    Up       0  1 SE  299968   299872 P2MP_INGRESS-to-R7_1
Total 3 displayed, Up 3, Down 0

{master}[edit]
regress@pro9-d# run show mpls lsp p2mp logical-system MP extensive 
Ingress LSP: 0 sessions
Total 0 displayed, Up 0, Down 0

Egress LSP: 0 sessions
Total 0 displayed, Up 0, Down 0

Transit LSP: 3 sessions
P2MP name: P2MP_1, P2MP branch count: 3

10.0.0.10
  From: 10.255.165.3, LSPstate: Up, ActiveRoute: 0
  LSPname: P2MP_INGRESS-to-PHOP_2, LSPpath: Primary
  P2MP LSPname: P2MP_1
  Suggested label received: -, Suggested label sent: -
  Recovery label received: -, Recovery label sent: 3
  Resv style: 1 SE, Label in: 299952, Label out: 3
  Time left:  119, Since: Wed Oct 14 16:50:51 2009
  Tspec: rate 0bps size 0bps peak Infbps m 20 M 1500
  Port number: sender 8 receiver 41925 protocol 0
  PATH rcvfrom: 1.1.1.8 (fe-1/3/2.1) 53 pkts
  Adspec: received MTU 1500 sent MTU 1500
  PATH sentto: 1.1.4.10 (fe-1/3/2.4) 53 pkts
  RESV rcvfrom: 1.1.4.10 (fe-1/3/2.4) 53 pkts
  Explct route: 1.1.4.10                
  Record route: 1.1.6.1 1.1.11.7 1.1.1.8 <self> 1.1.4.10  

10.0.0.11
  From: 10.255.165.3, LSPstate: Up, ActiveRoute: 0
  LSPname: P2MP_INGRESS-to-EGRESS_3, LSPpath: Primary
  P2MP LSPname: P2MP_1
  Suggested label received: -, Suggested label sent: -
  Recovery label received: -, Recovery label sent: 299872
  Resv style: 1 SE, Label in: 299952, Label out: 299872
  Time left:  119, Since: Wed Oct 14 16:50:51 2009
  Tspec: rate 0bps size 0bps peak Infbps m 20 M 1500
  Port number: sender 8 receiver 41925 protocol 0
  PATH rcvfrom: 1.1.1.8 (fe-1/3/2.1) 53 pkts
  Adspec: received MTU 1500 sent MTU 1500
  PATH sentto: 1.1.4.10 (fe-1/3/2.4) 53 pkts
  RESV rcvfrom: 1.1.4.10 (fe-1/3/2.4) 53 pkts
  Explct route: 1.1.4.10 1.1.2.11 
  Record route: 1.1.6.1 1.1.11.7 1.1.1.8 <self> 1.1.4.10 1.1.2.11  

10.0.0.6
  From: 10.255.165.3, LSPstate: Up, ActiveRoute: 0
  LSPname: P2MP_INGRESS-to-R7_1, LSPpath: Primary
  P2MP LSPname: P2MP_1                  
  Suggested label received: -, Suggested label sent: -
  Recovery label received: -, Recovery label sent: 299872
  Resv style: 1 SE, Label in: 299968, Label out: 299872
  Time left:  120, Since: Wed Oct 14 16:50:51 2009
  Tspec: rate 0bps size 0bps peak Infbps m 20 M 1500
  Port number: sender 8 receiver 41925 protocol 0
  PATH rcvfrom: 1.1.10.4 (fe-1/3/2.10) 53 pkts
  Adspec: received MTU 1500 sent MTU 1500
  PATH sentto: 1.1.4.10 (fe-1/3/2.4) 53 pkts
  RESV rcvfrom: 1.1.4.10 (fe-1/3/2.4) 53 pkts
  Explct route: 1.1.4.10 1.1.12.5 1.1.9.6 
  Record route: 1.1.6.1 1.1.11.7 1.1.8.8 1.1.7.3 1.1.10.4 <self> 1.1.4.10 1.1.12.5 1.1.9.6  
Total 3 displayed, Up 3, Down 0

{master}[edit]
regress@pro9-d# 

<h2><a name="ShowCmdBackup"></a>Sample Show Commands Output in Backup</h2>

<b>Backup: Transit</b>
<b>Backup: Ingress</b>

{backup}[edit]
regress@pro9-b1# run show mpls lsp p2mp 
Ingress LSP: 1 sessions
P2MP name: P2MP_1, P2MP branch count: 3
To              From            State Rt P     ActivePath       LSPname
10.0.0.10       0.0.0.0         Dn     0       -                P2MP_INGRESS-to-PHOP_2
10.0.0.6        0.0.0.0         Dn     0       -                P2MP_INGRESS-to-R7_1
10.0.0.11       0.0.0.0         Dn     0       -                P2MP_INGRESS-to-EGRESS_3Total 3 displayed, Up 0, Down 3

Egress LSP: 0 sessions
Total 0 displayed, Up 0, Down 0

Transit LSP: 1 sessions
Total 0 displayed, Up 0, Down 0

{backup}[edit]
regress@pro9-b1# run show mpls lsp p2mp detail 
Ingress LSP: 1 sessions
P2MP name: P2MP_1, P2MP branch count: 3

10.0.0.10
  From: 0.0.0.0, State: Dn, ActiveRoute: 0, LSPname: P2MP_INGRESS-to-PHOP_2
  ActivePath: (none)
  P2MP name: P2MP_1
  LoadBalance: Random
  Encoding type: Packet, Switching type: Packet, GPID: IPv4
  Primary   BR3_via_ING2     State: Dn
    Priorities: 7 0
    SmartOptimizeTimer: 180
    Will be enqueued for recomputation in 22 second(s).

10.0.0.6
  From: 0.0.0.0, State: Dn, ActiveRoute: 0, LSPname: P2MP_INGRESS-to-R7_1
  ActivePath: (none)
  P2MP name: P2MP_1
  LoadBalance: Random
  Encoding type: Packet, Switching type: Packet, GPID: IPv4
  Primary   BR2_via_R2       State: Dn
    Priorities: 7 0
    SmartOptimizeTimer: 180
    Will be enqueued for recomputation in 20 second(s).

10.0.0.11
  From: 0.0.0.0, State: Dn, ActiveRoute: 0, LSPname: P2MP_INGRESS-to-EGRESS_3
  ActivePath: (none)
  P2MP name: P2MP_1
  LoadBalance: Random
  Encoding type: Packet, Switching type: Packet, GPID: IPv4
  Primary   BR1_via_R3       State: Dn
    Priorities: 7 0
    SmartOptimizeTimer: 180
    Will be enqueued for recomputation in 10 second(s).
Total 3 displayed, Up 0, Down 3

Egress LSP: 0 sessions
Total 0 displayed, Up 0, Down 0

Transit LSP: 1 sessions
Total 0 displayed, Up 0, Down 0

{backup}[edit]
regress@pro9-b1# 

<hr><h2><a name="note"></a>Notes</h2>
<hr><h2><a name="glos"></a>Glossary</h2>
<hr><h2><a name="revi"></a>Review Comments</h2>
<b>Meeting Notes: 11/06 2PM PST</b>
<b>Attendees: avneesh, ravis, hsitaraman, ina, krajkotia</b>

lsp statistics are for per sub lsp.
  clear caveats continues to exist

graceful restart: Ingress graceful restart correctly
                  Pick up the next-hops from the proper list

Any limitation on the number of branches of p2mp ?

Composites, when are they coming ?
Branches come and go might be buggy wrt max limit
  platform testing part
  Desired: Give priority to next-hops already in the kernel after swith over
End of November

Adding per p2mp lsp flood-nh display capability
Adding log history to floods
Add caveat wrt remerge leader election changes during switch-over

GRACEFUL-RESTART

egress: upstream label allocation is not supported 
Caveat: node protection
  p2mp link protection: 
  p2mp branches should select the same bypass

cspf for parallel links: Picks one and rest of the lsps should pick the same

switch-over:
Infra work for reconciliation
Add sanity checks for p2mp tree and trigger MBB for the tree

------------------------------------------------------------------------

Review comments by mail from Harish:

o Clarify addition of 'label' to p2mp flood nexthop application key structure
o Clarify CSPF role in parallel links environment for p2mp lsps nexthop selection
o Add p2mp remerge leader out of sync issue explicitly to caveats
o Clarify p2mp_pvc_id usage (is it really necessary to replicate it ?)

Review comments by mail from Avneesh:
o Add a note to 'non-goals' that minimizing traffic-loss is still a goal during
  make-before-break for Ingress P2MP LSPs
o Clarify when NSR support for link-protection comes in. (It comes in the second
  phase). Need to disable this from getting executed in the initial phase of
  transit.
o Try to add next-hop list information as argument to the new APIs introduced

</pre>
</html>
